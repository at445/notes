# 附录一：

📌**CPI**

​	CPI（Cycles Per Instruction）指**每条指令平均时钟周期数**，衡量 CPU 执行效率，**只有加权平均 CPI 具有实际意义**。比如：有 5 类指令，CPI 分别为 1、2、3、4、5个时钟周期，假设一个程序中五类指令各占 20%，则加权平均 CPI = 1×0.2 + 2×0.2 + 3×0.2 + 4×0.2 + 5×0.2 = 3。

​	引入流水线是提高CPI的方式，比如还是上面的例子假设引入了三级流水线，流水线的每个stage的时间都严格相等，因为级数小于最大指令的周期数这时候加权平均CPI= 1×0.2 + 1×0.2 + 1×0.2 + 2×0.2 + 3×0.2 = 1.6；假设引入了5级流水，这个是时候的加权平均数就变成了1。但是，实际按照体系架构的不一样，流水设计会被固化成固定的段。

📌**加速比**

引入流水线以后在理想流水线（各级完美平衡、无冲突、无停顿）中，每条指令的平均时间可由以下公式计算：

理想流水线中每条指令的平均时间$= \dfrac{\text{非流水线每条指令时间}}{\text{流水级的数目 } n}$

同时，实现流水线得到的**加速比 = 流水级数目 n**，即理论上性能提升 n 倍。比如：非流水线中一条指令需要 10 个时钟周期完成。理想 5 级流水线也就是每个阶段 2 个周期。那么此时的加速比就是原来的 5 倍。

📌**CPI 与吞吐率（IPC）的关系**

- **CPI（Cycles Per Instruction）**：执行一条指令平均需要的时钟周期数，衡量指令执行的 “成本”。
- **IPC（Instructions Per Cycle）**：每个时钟周期完成的指令数，衡量 CPU 的吞吐率。
- 二者互为倒数。
- 在理想流水线中，虽然单条指令的总延迟可能仍较高（如 10 周期），但指令重叠执行使得吞吐率大幅提升，平均到每条指令上的周期数（CPI）趋近于 1，此时 IPC 也趋近于 1。

---

>**不同体系结构的流水线设计**
>
>| 架构类型                   | 核心体系结构（更严谨表述）                                   | 流水线设计核心特征（更通用）                                 | 关键特点（冲突 / 调度 / 效率）                               | ��型流水线阶段（简化示���）                                  | 适用场景                                |
>| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------------- |
> | **通用 CPU（x86/ARM）**    | **对外：统一存储模型（冯·诺依曼语义为主）**；**对内：I/D 分离缓存的混合哈佛实现** | ① 经典 RISC 可用 5 级流水作教学抽象；② 现实高性能核多为**深流水 + 宽发射 +（常见）乱序执行**；③ x86 常见 **译码→μop**（以及 μop cache 等） | ① **结构/数据/控制**冲突都需要处理；② 大量依赖 **分支预测、投机、寄存器重命名、动态调度**；③ 目标常是提高 IPC（不必强行“CPI≈1”） | 前端：取指/预测→译码/μop→分派；后端：执行→访存→提交/写回     | 桌面 / 服务器 / 移动终端（通用计算）    |
>  | **GPU**                    | **多核/众核 + SIMD/SIMT 执行模型**；片上多级存储（寄存器/共享存储/L1/L2） | ① 以 **warp/wavefront** 为基本调度粒度；② 多管线并行执行（标量/向量 ALU、Load/Store、纹理等），通过**线程级并行**隐藏长延迟；③ 前端控制相对简单但并非“无分支” | ① 典型瓶颈：**存储带宽/访存延迟**；② 对分支分歧敏感（倾向保持控制流一致性）；③ 调度常为**硬件线程调度 + 编译/运行时协同**；④ 强调吞吐（Throughput）> 单线程延迟 | 取指→译码/发射→SIMT/SIMD 执行→（访存/纹理）→写回/回收        | 图形渲染 / GPGPU（并行吞吐计算）        |
>  | **DSP**                    | 多采用**哈佛或改进哈佛**；常见 MAC/饱和算术/定点优化；部分支持 SIMD/VLIW/多发射 | ① 常见 **多发射/（部分为）VLIW** 或 SIMD；② 面向信号处理的**专用功能单元流水化**；③ 更强调确定性、低功耗、实时性 | ① I/D 分离可降低部分冲突，但仍可能有**端口/Bank/功能单元争用**；② 更多依赖**编译期静态调度**（也可能有少量动态机制）；③ 追求低延迟/低功耗/稳定吞吐 | 取指→译码→发射（可打包）→多单元并行执行→写回                 | 信号处理 / 基带 / 音视频编解码（实时）  |
>  | **NPU（昇腾 / 寒武纪等）** | **控制处理器 + 专用张量/矩阵计算阵列**；常见片上 SRAM/NoC；整体更接近“加速器/数据搬运主导” | ① 控制面：指令/任务调度（可能类 VLIW/向量 ISA/任务队列）；② 计算面：**矩阵/张量单元（如 systolic/矩阵乘阵列）**流水；③ 通过算子/图级调度提高数据复用 | ① 冲突形态从“传统三大冲突”转向：**带宽、片上存储容量、Bank 冲突、DMA/NoC 仲裁、算子同步**；② 通常**静态（编译/图）调度为主**，辅以运行时队列；③ 关键指标：利用率、带宽匹配、能效（TOPS/W） | 控制流：取指/派发→调度→同步；数据流：预取/搬运→阵列计算→写回/融合 | AI 推理 / 训练（张量/矩阵）             |
>  | **TPU（谷歌）**            | 面向张量计算的加速器：**控制核 + systolic array + 片上存储**；整体偏“数据流式/流处理” | ① 控制面简单、以批处理/大块算子为主；② 计算面：**systolic array 流水**；③ 通过编译器/运行时把计算组织成高复用的数据路径 | ① 并非“零冲突”，主要瓶颈同样在**数据供给、片上存储、带宽与调度**；② 通过大粒度算子与静态规划降低控制复杂度；③ 极强调能效与吞吐 | 控制：调度/启动→同步；数据：搬运→阵列流水计算→存储           | 大规模 AI 推理/训练（取决于代际与配置） |

---

> **NPU上的对应概念**
>
> 1. "指令"是什么？
>
>    跟CPU不同，NPU上的指令不再是instruction或者 μop，而是：
>
>    ​	算子任务（op task）：一次GEMM/Conv/Attention kernel的启动
>
>    ​        tile任务（tile task）：把大张量分块后，每一块的load/compute/store
>
>    ​        数据流token（dataflow）：在 systolic array 中每拍注入/传播的数据
>
> 2. “指令”怎么评估？
>
>    每周期发射的指令数（IPC）→ “**每个单位时间能完成多少tile/输出多少元素**”。
>
>    每条指令需要的周期数（CPI）→ “**阵列利用率、吞吐、重叠率、带宽利用率**”。
>
> 3. 典型流水线阶段
>
>    **Load/Prefetch**：HBM/DDR → 片上 SRAM（或 L2）
>
>    **Compute**：SRAM/寄存器 → 张量阵列（MMA/systolic）计算
>
>    **Store/Writeback**：结果写回 SRAM → HBM，或直接供下游算子消费
>
>    中间使用到的设计有：
>
>    **double buffering / ping-pong buffer**：让 Load 与 Compute 重叠（类似用缓冲解耦流水段）。
>
>    **软件流水（software pipelining）**在 NPU 上常以“tile 级任务编排”形式出现：当 tile(i) 计算时，tile(i+1) 预取，tile(i-1) 写回。
>
>    三段式（Load/Compute/Store）+ 双缓冲把每个 tile 的有效节拍从 (T_L+T_C+T_S) 变成 (\max(T_L,T_C,T_S))，从而让端到端吞吐更接近 roofline 假设的“算力与带宽谁慢谁决定”的上界。3) 把“冒险/冲突”映射到 NPU：仍然三类，但形式变了
>
>    书里讲三类 hazard：结构、数据、控制。NPU 也有，只是表现不同。
>
>    ### 3.1 结构冲突（Structural hazards）→ 存储/互连/端口争用
>
>    CPU：功能单元不够、单端口存储器等。
>    NPU 常见结构冲突：
>
>    - **HBM 带宽争用**（多算子/多流并发）
>    - **NoC 拥塞与仲裁**（多个计算簇同时搬运）
>    - **SRAM 端口不足 / bank 冲突**（地址映射导致同 bank 热点）
>    - **DMA 引擎数量/队列深度不足**（导致排队）
>
>    这些冲突在 profile 上常表现为：DMA wait、NoC stall、SRAM conflict、队列 backpressure。
>
>    ### 3.2 数据冲突（Data hazards）→ tile 依赖、producer-consumer、部分和（partial sum）
>
>    CPU：RAW/WAR/WAW，靠转发/重命名。
>    NPU 的“数据冒险”更多是：
>
>    - **tile 依赖**：tile(i) 的输出是 tile(i+1) 的输入（跨算���尤其明显）
>    - **partial sum 依赖**：K 维分块的 GEMM/Conv 需要累加，多次访问输出块
>    - **布局/重排依赖**：transpose/reshape 必须先完成才能喂给下游
>
>    对应解决手段：
>
>    - 片上累加（减少写回、降低依赖代价）
>    - producer-consumer pipeline（让上游输出不落 HBM，直接片上接力）
>    - 通过 fusion 消掉中间张量边界
>
>    ### 3.3 控制冲突（Control hazards）→ 动态 shape、分支分歧、运行时调度不确定性
>
>    NPU 很少做复杂分支预测，但控制不确定性来自：
>
>    - **动态 shape / 动态 batch / 动态序列长度**（尤其 NLP）
>    - 多模型并发的资源抢占导致时序抖动
>    - 某些算子包含数据相关循环/条件（例如稀疏、topk、NMS 等）
>
>    对应策略更像“编译器+运行时”协作：
>
>    - 多版本编译（shape specialization）+ runtime dispatch
>    - 更粗粒度的任务图调度，减少细粒度分支
>    - 对不规则算子回退到向量核/CPU 或专用实现
>
>    ------
>
>    ## 4) NPU 版“转发、旁路、暂停”：核心是缓冲、预取与同步原语
>
>    CPU 里的转发(bypassing)是寄存器级的；NPU 对应的是**数据在存储层级间的旁路**：
>
>    - **旁路/直连（bypass）**：上游算子输出直接进入下游输入缓冲（片上），避免落 HBM
>    - **预取（prefetch）**：提前把下一 tile 搬到片上（隐藏带宽延迟）
>    - **暂停（stall）**：当下游 buffer 满、或 NoC 拥塞时，上游 DMA/compute 被迫停（backpressure）
>    - **同步（barrier/event/semaphore）**：替代 CPU 的冒险检测逻辑，用显式事件表达依赖
>
>    所以你可以把 NPU 里的“hazard control unit”理解成：
>
>    > 编译期计划 + 运行时队列/事件系统 + buffer 管理，一起实现“何时能发射下一块 tile”。
>
>    ------
>
>    ## 5) NPU 的“流水线深度/启动开销”：fill & drain 是你要新增的概念
>
>    书里讲流水线启动与排空对短程序的影响。NPU 上这个影响更直观：
>
>    - **systolic array / MMA 阵列**有明显的 **fill（填充）/drain（排空）**阶段
>    - tile 太小会导致稳态时间很短，fill/drain 占比高 → 利用率低
>    - 维度不整除阵列导致尾块处理（padding/fragmentation）→ 类似“流水线气泡”
>
>    因此 NPU 编译器很在意：
>
>    - 选更合适的 tile，让阵列跑更久稳态
>    - 将多个小算子融合成更大 kernel，减少反复 fill/drain 与 launch 开销
>
>    ------
>
>    ## 6) 性能度量：从 CPI/IPC → 吞吐、利用率、重叠率（对应量化方法）
>
>    量化研究方法那本书强调用公式与测量拆解性能。NPU 你可以这样做同构映射：
>
>    ### 6.1 NPU 版“CPI 分解”思路
>
>    CPU：CPI = base + stall_mem + stall_branch + …
>    NPU：可以类比做“时间占比”分解：
>
>    - T_total = max( T_compute_path, T_memory_path, T_sync_path ) + overhead 并进一步拆：
>    - memory_path：HBM 读写、NoC、SRAM bank 冲突、DMA 排队
>    - compute_path：阵列 fill/drain、算子内部流水效率、向量核瓶颈
>    - sync_path：barrier 等待、producer-consumer 不匹配
>
>    ### 6.2 Roofline（强烈建议你在读这章时同步引入）
>
>    对 NPU 更贴合的上界分析：
>
>    - 算强度（FLOPs/Byte）
>    - 峰值算力与峰值带宽
>    - 判断是 compute-bound 还是 bandwidth-bound 然后决定优化方向：融合/复用/tiling/布局/减少写回等。
>
>    ------
>
>    ## 7) 你在读“基础与中级流水线”时，可以同步建立的 NPU 对照表（速记）
>
>    - 指令级流水段 → tile 级 Load/Compute/Store 段
>    - forward/bypass → 片上 producer-consumer 旁路、融合
>    - stall → backpressure（buffer 满、NoC/HBM 拥塞）
>    - structural hazard → 带宽/端口/NoC/DMA 争用
>    - data hazard → tile 依赖、partial sum 累加依赖
>    - control hazard → 动态 shape 与运行时调度不确定
>    - pipeline fill/drain → 阵列填充/排空 + 小 tile 低利用率
>    - CPI/IPC → 利用率、吞吐、重叠率、带宽利用率
>
>    ------
>
>    ## 8) 建议你在这一章读完后做的 3 个“最小练习”（不依赖具体芯片）
>
>    1. **画一条三段式时间线**：同一个 GEMM 分块后，标出 prefetch/compute/store 如何重叠，哪里会 bubble。
>    2. **做一次 roofline 判断**：任选一个算子（GEMM、layernorm、softmax），写出它的近似 FLOPs 和 bytes，判断更偏 compute-bound 还是 memory-bound。
>    3. **列出 5 种 bubble 来源**并给出对应优化：例如 bank 冲突→改 layout/对齐；HBM 带宽不足→提高复用/融合；同步过多→增大 tile/合并任务等。

